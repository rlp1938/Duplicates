.TH DUPLICATES 1 "v\ 1.0.2" "2014-05-15" "GNU"
.SH NAME
.B duplicates
\- Generate a list of duplicated files in user input dir.
.SH SYNOPSIS
duplicates \fIdir [dir ...]\fR > \fIdups.lst\fR
.br
duplicates \fIdir [dir ...]\fR > \fIdups.lst\fR 2> \fIbroken_links\fR
.br
.SH OPTIONS
.TP
\-h, prints a brief help message.
.TP
\-d, don't delete the workfiles in \fI/tmp\fR
.TP
\-v, each invocation increases verbosity, default is 0.
.br
.RS
0, emit no progress information.
.br
1, emit information of each new section started.
.br
2, emit pathname of each 100th file during Md5sum generation.
.br
3, the same for every tenth file.
.br
4+, the same for every file.
.RE
.br
You probably do not want to use this option when you are redirecting
.br
\fIstderr\fR to a file. Eg 2> \fIerrors_file\fR
.SH DESCRIPTION
When run to conclusion a total of 5 workfiles will be created in /tmp.
.br
The filenames are of the form \fI$USERduplicates0\fR .. \fI$USERduplicates4\fR
.br
The program works by sorting on size bytes, inode number, then path to
.br
file. Files of unique size are discarded, then for files of identical
.br
size and inode number, being mutually linked, all but the last record
.br
is discarded. Files of like size and different inodes are compared byte
.br
by over the lesser of filesize or 12k kb, Only if such files are the
.br
same an md5sum hash is calculated. If the hashes match then these files
.br
are output as duplicates.
.br
After sorting on md5sum, inode, and path, the first path in any cluster
.br
of identical md5sums is prepended to the records and the result sorted.
.br
Hopefully such an ordering makes the output more useable for analysis
.br
since the consequences of having done recursive copying of directories
.br
will be more apparent.
.br
The result is sent to \fIstdout.\fR
.br
Errors where they occur are sent to \fIstderr\fR as also is the result of
.br
of selecting any level of verbosity.
.br
NB zero length files are never taken into account in this program.
.br
.SH FILES
There is a configuration file \fI$HOME/.congfig/duplicates/excludes\fR
.br
in which is recorded some strings to identify paths which are not
.br
needed to test for duplication.  Some of these are there because the
.br
files are volatile and change size during the course of the run.
.br
Any files that do change size during the run will be recorded in
.br
.IR ./comparison_errors " for perusal and possible editing of the"
.br
configuration file. The errors file is automatically unlinked if empty.
.br
.SH VERSION
This documentation describes \fBduplicates\fR version 1.0.3
.SH "SEE ALSO"
bigfiles(1), brokensym(1), oldfiles(1), processdups(1), zapfiles(1),
cleanuputils(7)
.br
